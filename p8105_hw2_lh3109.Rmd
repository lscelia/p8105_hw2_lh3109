---
title: "p8105_hw2_lh3109"
author: "Lesi He"
output: html_document
---


```{r, echo = FALSE, message=FALSE}
library(tidyverse)
library(readxl)
library(dplyr)

```

## Problem 1
```{r, message = FALSE}
#import Mr. Trash Wheel sheet from the excel file
mr_trash_wheel_df = 
  read_excel(
    "data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx", 
    sheet = 1,
    range = "A2:N534"
  ) %>% 
  #clean variable names
  janitor::clean_names() %>% 
  #omit rows that do not include dumpster-specific data
  filter(!is.na(dumpster)) %>% 
  #round the sports_balls values
  mutate(sports_balls = round(sports_balls)) 


#get median of the number of sports_balls
sports_balls_median = median(pull(mr_trash_wheel_df, "sports_balls"))
sports_balls_median
mr_trash_wheel_df

#import precipitation 2019 data
precip_2019_df = 
  read_excel(
    "data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx", 
    sheet = 6,
    range = "A2:B14"
    ) %>% 
  #clean variable names
  janitor::clean_names() %>% 
  #add year variable
  mutate(year = "2019", 
         month = month.name[month]
         )


#import precipitation 2018 data
precip_2018_df = 
  read_excel(
    "data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx", 
    sheet = 7,
    range = "A2:B14"
    ) %>% 
  #clean variable names
  janitor::clean_names() %>% 
  #add year variable
  mutate(year = "2018", 
         month = month.name[month]
         ) 

left_join(precip_2019_df, precip_2018_df, by = "month")
```


The Mr. Trash Wheel's data suggests that the number of sports_balls are generally increasing. The combined data set for 2018 and 2019 precipitation suggest that amount of precipitation varies a lot by each month. For instance, when there was higher amount of precipitation in January 2019, there was little precipitation in January 2018, and vice versa. The total precipitation in 2018 is 70.33 inch. The median number of sports ball in s dumpster in 2019 is 9.


## Problem 2

```{r}
#import pols_month data
pols_month_df = 
  read_csv("data/pols-month.csv") %>% 
  #create better variable names
  janitor::clean_names() %>% 
  #separate month into three variables
  separate(mon, into = c("year", "month", "day")) %>% 
  #manipulate columns:
  mutate(month = month.name[as.numeric(month)],
         president = prez_gop + prez_dem,
         ) %>% 
  #remove columns:
  select(-day,
         -prez_gop,
         -prez_dem
         )

#pols_month_df


#import snp data
snp_df = 
  read_csv("data/snp.csv") %>% 
  #create better variable names
  janitor::clean_names() %>% 
  #convert the date variable to proper format
  mutate(date = as.Date(as.character(date), format = "%d/%m/%y")) %>% 
  #separate date into three variables
  separate(date, into = c("year", "day", "month")) %>% 
  #change the month variable
  mutate(month = month.name[as.numeric(month)]) %>% 
  #remove day variable
  select(-day) %>% 
  #make year variable become the heading variable
  relocate("year")

#There was a error in the function as.Date() where year 1950-1968 was converted to 2050-2068
#I was unable to find a better way to replace as.Date() to a better function
#To fix this problem:
snp_df <- mutate(snp_df, year = ifelse(as.numeric(year) >= 2050, as.numeric(year) - 100, year))

#snp_df


#import unemployment data
unemployment_df = 
  read_csv("data/unemployment.csv",
           col_names = c("year", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12")) %>% 
  .[-1,] %>% 
  pivot_longer(
    "1":"12",
    names_to = "month",
    values_to = "precentage") %>% 
  mutate(month = month.name[as.numeric(month)])
  

#unemployment_df

join_colsmonth_snp = left_join(pols_month_df, snp_df, by = c("month","year"))
join_colsmonth_snp_unemply = left_join(join_colsmonth_snp, unemployment_df, by = c("month","year"))
join_colsmonth_snp_unemply 


#join_colsmonth_snp_unemply  %>%
    #ggplot(aes(x = year, y = rep_dem)) +
    #geom_point()
```

The pols-month data set contains observations related to the president, governors, senators and representative related to the number of national politicians who are democratic or republican at any given time. The snp data set contains observations of related to the closing values of the Standard & Poor's stock market index associated with date. The unemployment data set contains the percentage of unemployment with respect to month and date. The final "join_colsmonth_snp_unemply" data set combines these three data set by matching them with specific month and year. Based on this data set, we can see that the unemployment percentage, though fluctuate, is slightly increasing over years form 1950 to 2050. The value of close is experiencing exponential growth in these years. The number of democratic governors first increased by years, reached maximum at around 1997, then gradually decreased. Similarly, the number of democratic senators and democratic representatives follows the similar pattern over these years.



## Problem 3
```{r}
#read the csv file
baby_names_df = 
  read_csv("data/Popular_Baby_Names.csv", col_types = "icccii") %>% 
  #create better variable names
  janitor::clean_names() %>% 
  #remove duplicated names
  distinct() 

olivia_df = 
  #filter by the name "Olivia"
  filter(baby_names_df, childs_first_name == "Olivia") %>%
  #produce table for "Olivia" summarizing rank over years
  pivot_wider(
    ethnicity,
    names_from = "year_of_birth",
    values_from = "rank"
  ) %>% 
  knitr::kable()

popular_male_df = 
  #filter by gender
  filter(baby_names_df, gender == "MALE") %>% 
  #group the names by year
  group_by(year_of_birth) %>% 
  #extract the rows with highest counts of a name
  slice(which.max(count)) %>% 
  knitr::kable()


nonhis_m_2016_df = 
  #filter the dataframe by gender, year of birth and ethnicity
  filter(baby_names_df, gender == "MALE", year_of_birth == 2016, grepl("NON HISPANIC", ethnicity)) %>% 
  group_by(childs_first_name)

#create scatter plot for nonhis_male_2016_df
ggp_nonhis_m_2016 = 
  nonhis_m_2016_df %>%
    ggplot(aes(x = rank, y = count)) +
    geom_point()
  

olivia_df
popular_male_df
nonhis_m_2016_df
ggp_nonhis_m_2016
```




